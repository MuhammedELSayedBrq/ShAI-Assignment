{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9veqgG-LVKd3"
      },
      "source": [
        "#About Dataset\n",
        "salaries dataset generally provides information about the employees of an organization in relation to their compensation. It typically includes details such as how much each employee is paid (their salary), their job titles, the departments they work in, and possibly additional information like their level of experience, education, and employment history within the organization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZwHdpBfVzOh"
      },
      "source": [
        "# Features\n",
        "- 'Id'\n",
        "- 'EmployeeName'\n",
        "- 'JobTitle'\n",
        "- 'BasePay'\n",
        "- 'OvertimePay'\n",
        "- 'OtherPay'\n",
        "- 'Benefits'\n",
        "- 'TotalPay' -> salary\n",
        "- 'TotalPayBenefits'\n",
        "- 'Year'\n",
        "- 'Notes'\n",
        "- 'Agency'\n",
        "- 'Status'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1VJposzVrSF"
      },
      "source": [
        "# Tasks\n",
        "\n",
        "1. **Basic Data Exploration**: Identify the number of rows and columns in the dataset, determine the data types of each column, and check for missing values in each column.\n",
        "\n",
        "2. **Descriptive Statistics**: Calculate basic statistics mean, median, mode, minimum, and maximum salary, determine the range of salaries, and find the standard deviation.\n",
        "\n",
        "3. **Data Cleaning**: Handle missing data by suitable method with explain why you use it.\n",
        "\n",
        "4. **Basic Data Visualization**: Create histograms or bar charts to visualize the distribution of salaries, and use pie charts to represent the proportion of employees in different departments.\n",
        "\n",
        "5. **Grouped Analysis**: Group the data by one or more columns and calculate summary statistics for each group, and compare the average salaries across different groups.\n",
        "\n",
        "6. **Simple Correlation Analysis**: Identify any correlation between salary and another numerical column, and plot a scatter plot to visualize the relationship.\n",
        "\n",
        "8. **Summary of Insights**: Write a brief report summarizing the findings and insights from the analyses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "KmZfk5xkXI2y",
        "outputId": "e77ffddb-f533-4bac-d15a-3ea9f42b7890"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('Salaries.csv')\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIT514wlvvBZ",
        "outputId": "9ecf152c-554a-4cf6-d667-efc95c16d489"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbIN2ujHUyRx"
      },
      "source": [
        "**Basic Data Exploration**: Identifing the number of rows and columns in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dovy31FUyUF"
      },
      "outputs": [],
      "source": [
        "rows = df.shape[0]\n",
        "columns = df.shape[1]\n",
        "print(f\"Number of rows is {rows}\")\n",
        "print(f\"Number of rows is {columns}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HE9jbRjcUyoX"
      },
      "source": [
        "**Basic Data Exploration:** Determining the data types of each column, and checking for missing values in each column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_types = df.dtypes\n",
        "missing_values = df.isnull().sum()\n",
        "\n",
        "print(f\"Data types are : {data_types}\" )\n",
        "print(f\"Data types are : {missing_values}\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_copy = df.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Descriptive Statistics**: Calculating basic statistics mean, median, mode, minimum, and maximum salary, determining the range of salaries, and finding the standard deviation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "salaries_mean = round(df_copy['TotalPay'].mean() , 2 )\n",
        "salaries_median = round( df_copy['TotalPay'].median() , 2 )\n",
        "salaries_mode = df_copy['TotalPay'].mode().iloc[0]\n",
        "salaries_min = df_copy['TotalPay'].min()\n",
        "salaries_max = df_copy['TotalPay'].max()\n",
        "salary_range = [salaries_min , salaries_max]\n",
        "salaries_standard_deviation = round( df_copy['TotalPay'].std() , 2 )\n",
        "\n",
        "print(f\"Mean of salaries: {salaries_mean}\")\n",
        "print(f\"Median of Salaries: {salaries_median}\")\n",
        "print(f\"Mode of Salaries: {salaries_mode}\")\n",
        "print(f\"Minimum Salary: {salaries_min}\")\n",
        "print(f\"Maximum Salary: {salaries_max}\")\n",
        "print(f\"Salary Range: from {salary_range[0]} to {salary_range[1]}\")\n",
        "print(f\"Standard Deviation of Salary: {salaries_standard_deviation}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Exploring why we got zero mode && negative minmum salary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_copy['TotalPay'].value_counts().sort_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Data Cleaning:**\n",
        "Clean Zero and negative Salaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_copy = df_copy[df_copy['TotalPay'] > 0]\n",
        "salaries_mean = round(df_copy['TotalPay'].mean() , 2 )\n",
        "salaries_median = round( df_copy['TotalPay'].median() , 2 )\n",
        "salaries_mode = df_copy['TotalPay'].mode().iloc[0]\n",
        "salaries_min = df_copy['TotalPay'].min()\n",
        "salaries_max = df_copy['TotalPay'].max()\n",
        "salary_range = [salaries_min , salaries_max]\n",
        "salaries_standard_deviation = round( df_copy['TotalPay'].std() , 2 )\n",
        "\n",
        "print(f\"Mean of salaries: {salaries_mean}\")\n",
        "print(f\"Median of Salaries: {salaries_median}\")\n",
        "print(f\"Mode of Salaries: {salaries_mode}\")\n",
        "print(f\"Minimum Salary: {salaries_min}\")\n",
        "print(f\"Maximum Salary: {salaries_max}\")\n",
        "print(f\"Salary Range: from {salary_range[0]} to {salary_range[1]}\")\n",
        "print(f\"Standard Deviation of Salary: {salaries_standard_deviation}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Checking if junk data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "min_res = df_copy[df_copy['TotalPay'] == 0.3]\n",
        "print(min_res)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Data Cleaning**: Handle missing data by Dropping method because Status and Notes has NaN values equal to size of Data_Set so dropped, also deleting non important columns, deleting Agency because it has zero information gain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_copy.drop(columns=['Status', 'Notes','Id','Agency'], inplace=True)\n",
        "columns_cleaned = df_copy.columns\n",
        "print(columns_cleaned)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cleaning and renaming some non-clean columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_copy['JobTitle'] = df_copy['JobTitle'].replace('POLICE OFFICER III', 'POLICE OFFICER 3')\n",
        "df_copy['JobTitle'] = df_copy['JobTitle'].replace('Police Officer 3', 'POLICE OFFICER 3')\n",
        "df_copy['JobTitle'] = df_copy['JobTitle'].replace('X-Ray Laboratory Aide', 'X-RAY LABORATORY AIDE')\n",
        "df_copy['JobTitle'] = df_copy['JobTitle'].replace('BOARD COMMISSION MEMBER, $200 PER MEETING', 'BOARD COMMISSION MEMBER')\n",
        "df_copy['JobTitle'] = df_copy['JobTitle'].replace('Battlion Chief, Fire Suppressi', 'Battalion Chief, Fire Suppress')\n",
        "df_copy['JobTitle'] = df_copy['JobTitle'].replace('BdComm Mbr, Grp2,M=$25/Mtg', 'BdComm Mbr')\n",
        "df_copy['JobTitle'] = df_copy['JobTitle'].replace('BdComm Mbr, Grp3,M=$50/Mtg', 'BdComm Mbr')\n",
        "df_copy['JobTitle'] = df_copy['JobTitle'].replace('BdComm Mbr, Grp5,M$100/Mo', 'BdComm Mbr')\n",
        "df_copy['JobTitle'] = df_copy['JobTitle'].replace('Brd Comm Mbr, M=$200/Mtg', 'Brd Comm Mbr')\n",
        "df_copy['JobTitle'] = df_copy['JobTitle'].replace('Biologist', 'Biologist I/II')\n",
        "df_copy['JobTitle'] = df_copy['JobTitle'].replace('Chef', 'CHEF')\n",
        "df_copy['JobTitle'] = df_copy['JobTitle'].replace('Chemist', 'Chemist I/II')\n",
        "df_copy['JobTitle'] = df_copy['JobTitle'].replace('Commissioner No Benefits', 'Commissioner')\n",
        "df_copy['JobTitle'] = df_copy['JobTitle'].replace('Commissioner 16.700c, No Pay', 'Commissioner')\n",
        "df_copy['JobTitle'] = df_copy['JobTitle'].replace('Counselor, Family Court Svc', 'Counselor')\n",
        "df_copy['JobTitle'] = df_copy['JobTitle'].replace('Counselor, Juvenile Hall', 'Counselor')\n",
        "df_copy['JobTitle'] = df_copy['JobTitle'].replace('Counselor, Juvenile Hall SFERS', 'Counselor')\n",
        "df_copy['JobTitle'] = df_copy['JobTitle'].replace('Counselor, Log Cabin Ranch', 'Counselor')\n",
        "df_copy['JobTitle'] = df_copy['JobTitle'].replace('Counselor, Juvenile Hall SFERS', 'Counselor')\n",
        "df_copy['JobTitle'] = df_copy['JobTitle'].replace('Counselor,Log Cabin Rnch SFERS', 'Counselor')\n",
        "df_copy['JobTitle'] = df_copy['JobTitle'].replace('MANAGER VIII - MUNICIPAL TRANSPORTATION AGENCY', 'MANAGER VIII')\n",
        "df_copy['JobTitle'] = df_copy['JobTitle'].replace('SENIOR STATIONARY ENGINEER, SEWAGE PLANT', 'SENIOR STATIONARY ENGINEER')\n",
        "df_copy['JobTitle'] = df_copy['JobTitle'].replace('SENIOR STATIONARY ENGINEER, WATER TREATMENT PLANT', 'SENIOR STATIONARY ENGINEER')\n",
        "df_copy['JobTitle'] = df_copy['JobTitle'].replace('SENIOR STATIONARY ENGINEER, WATER TREATMENT PLANT', 'SENIOR STATIONARY ENGINEER')\n",
        "df_copy['JobTitle'] = df_copy['JobTitle'].replace('SENIOR STATIONARY ENGINEER, WATER TREATMENT PLANT', 'SENIOR STATIONARY ENGINEER')\n",
        "\n",
        "\n",
        "i = 50 \n",
        "j = 100\n",
        "df_sorted = df_copy['JobTitle'].value_counts().sort_index().iloc[i-1:j+1]\n",
        "print(df_sorted,\" from \",i,\"to \",j)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Data Cleaning:** Capitalizing all values to avoid repeating values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_copy['JobTitle'] = df_copy['JobTitle'].str.upper()\n",
        "df_copy['EmployeeName'] = df_copy['EmployeeName'].str.upper()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Basic Data Visualization**: Creating histograms to visualize the distribution of salaries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Histogram for Salary Distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df_copy['TotalPay'], bins=20, kde=True, color='skyblue')\n",
        "plt.title('Salary Distribution')\n",
        "plt.xlabel('Salary')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using pie chart to represent the proportion of employees in different departments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "department_counts = df_copy['JobTitle'].value_counts()\n",
        "plt.figure(figsize=(300,300))\n",
        "plt.pie(department_counts, labels=department_counts.index, autopct='%1.1f%%', startangle=90, colors=sns.color_palette('pastel'))\n",
        "plt.title('Proportion of Employees in Different Departments')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Grouped Analysis**: Grouping data by one or more columns and calculating summary statistics for each group, and comparing the average salaries across different groups."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grouped_df = df_copy.groupby('JobTitle')['TotalPay'].agg(['count', 'mean', 'median', 'min', 'max', 'std']).reset_index()\n",
        "\n",
        "print(grouped_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grouped_df_2 = df_copy.groupby('JobTitle')['BasePay'].describe()\n",
        "\n",
        "print(grouped_df_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grouped_data3 = df_copy.groupby(['EmployeeName', 'Year']).agg({\n",
        "    'BasePay': 'mean',\n",
        "    'OvertimePay': 'mean',\n",
        "    'OtherPay': 'mean',\n",
        "    'TotalPay': 'mean',\n",
        "    'TotalPayBenefits': 'mean'\n",
        "}).sort_values(by='TotalPay')\n",
        "print(grouped_data3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_copy.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Simple Correlation Analysis**: Identifing any correlation between salary and another numerical column, and plot a scatter plot to visualize the relationship."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "correlation = df['TotalPay'].corr(df['Year'])\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='Year', y='TotalPay', data=df_copy, color='coral')\n",
        "plt.title(f'Scatter Plot: Salary vs. Year\\nCorrelation: {correlation:.2f}')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Salary')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Saving Enhanced Dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "csv_path = 'Salaries_enhanced.csv'\n",
        "\n",
        "df_copy.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"The Clean and Enhanced DataFrame has been exported to '{csv_path}'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Key Findings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Cleaning Data**\n",
        "\n",
        "**1. Typo Errors in some Columns(Upper and Lower, Latin Numbers and English numbers, salary included in role,...etc)**\n",
        "\n",
        "**2. Non-sense TotalPay of zero and Negative values in salaries**\n",
        "\n",
        "**3. Status and Agency Does not contain any values so deleted and Agency is always San Francissco so no point of having it**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
